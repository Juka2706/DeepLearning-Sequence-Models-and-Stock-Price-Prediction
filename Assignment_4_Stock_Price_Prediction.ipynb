{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Advanced_Stock_Price_Prediction\n",
    "\n",
    "This notebook implements and compares two sequential models for stock price prediction using PyTorch, as per the assignment instructions.\n",
    "\n",
    "**Models:**\n",
    "1.  **Model 1:** A standard LSTM (Long Short-Term Memory) network.\n",
    "2.  **Model 2:** An LSTM network enhanced with an attention mechanism.\n",
    "\n",
    "**Objective:**\n",
    "Predict the *relative change* (log returns) of a stock's price and evaluate the models' performance using autoregressive prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports\n",
    "\n",
    "First, we import all necessary libraries and set up our environment, including the device (GPU if available) and key parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Set device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Create a 'models' directory if it doesn't already exist\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# --- Configuration Parameters ---\n",
    "STOCK_TICKER = \"BTC-USD\"    # Example: Bitcoin. You can change this.\n",
    "START_DATE = \"2014-01-01\"   # 10 years of data\n",
    "END_DATE = \"2024-11-01\"     # Today's date or recent\n",
    "\n",
    "TRAIN_SPLIT = 0.85          # 85% for training\n",
    "BASE_WINDOW_SIZE = 50       # Initial window size (50 days)\n",
    "\n",
    "# --- Model Hyperparameters ---\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100                # Max epochs (will use early stopping)\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "PATIENCE = 10               # For early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Data Acquisition\n",
    "\n",
    "We use the `yfinance` package to download the daily stock price data for our chosen ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Download data\n",
    "    data = yf.download(STOCK_TICKER, start=START_DATE, end=END_DATE)\n",
    "    \n",
    "    if data.empty:\n",
    "        print(f\"No data found for ticker {STOCK_TICKER}. Please check the ticker or date range.\")\n",
    "    else:\n",
    "        # We only need the 'Close' price\n",
    "        prices = data['Close']\n",
    "        \n",
    "        # Plot the downloaded data\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        prices.plot()\n",
    "        plt.title(f\"{STOCK_TICKER} Closing Price (Absolute)\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading data: {e}\")\n",
    "    print(\"Please see the 'Appendix: How to Add Data Manually' section at the end of this notebook.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "### 2.1. Calculate Relative Values (Log Returns)\n",
    "\n",
    "As instructed, we will predict relative values instead of absolute prices. We'll use **log returns**, which are defined as $\\log(P_t / P_{t-1})$. This transformation stabilizes the variance and makes the time series more stationary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log returns\n",
    "log_returns = np.log(prices / prices.shift(1))\n",
    "\n",
    "# Drop the first NaN value that results from the shift\n",
    "log_returns = log_returns.dropna()\n",
    "\n",
    "# Convert to numpy array for processing\n",
    "log_returns_np = log_returns.values.astype(np.float32)\n",
    "\n",
    "print(f\"Original price points: {len(prices)}\")\n",
    "print(f\"Log return points: {len(log_returns_np)}\")\n",
    "\n",
    "# Plot log returns\n",
    "plt.figure(figsize=(14, 7))\n",
    "log_returns.plot()\n",
    "plt.title(f\"{STOCK_TICKER} Daily Log Returns (Relative Change)\")\n",
    "plt.ylabel(\"Log Return\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 2.2. Create Sliding Window Dataset\n",
    "\n",
    "We implement a function to create our dataset based on the sliding window approach.\n",
    "-   **Input (X):** A sequence of `window_size` consecutive log returns.\n",
    "-   **Target (y):** The *next* log return immediately following the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_windows(data, window_size):\n",
    "    \"\"\"\n",
    "    Creates sliding window sequences (X) and corresponding targets (y).\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        # Input sequence (features)\n",
    "        X.append(data[i : i + window_size])\n",
    "        # Target value (the next day's log return)\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create the dataset\n",
    "X, y = create_sliding_windows(log_returns_np, BASE_WINDOW_SIZE)\n",
    "\n",
    "print(f\"Shape of X (Inputs): {X.shape}\")\n",
    "print(f\"Shape of y (Targets): {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 2.3. Split Data and Create DataLoaders\n",
    "\n",
    "We split the data (85% train, 15% test), convert it to PyTorch tensors, and create `DataLoaders` for batching during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate split index\n",
    "split_idx = int(len(X) * TRAIN_SPLIT)\n",
    "\n",
    "# Split the data\n",
    "X_train, y_train = X[:split_idx], y[:split_idx]\n",
    "X_test, y_test = X[split_idx:], y[split_idx:]\n",
    "\n",
    "# Reshape y to be (N, 1) for the loss function\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "print(f\"Training set: X shape {X_train.shape}, y shape {y_train.shape}\")\n",
    "print(f\"Test set:     X shape {X_test.shape}, y shape {y_test.shape}\")\n",
    "\n",
    "# --- Convert to PyTorch Tensors ---\n",
    "X_train_t = torch.tensor(X_train).float()\n",
    "y_train_t = torch.tensor(y_train).float()\n",
    "X_test_t = torch.tensor(X_test).float()\n",
    "y_test_t = torch.tensor(y_test).float()\n",
    "\n",
    "# LSTM expects input shape (N, L, H_in) where N=batch_size, L=seq_len, H_in=input_features\n",
    "# Our H_in is 1 (just the log return)\n",
    "if X_train_t.dim() == 2:\n",
    "    X_train_t = X_train_t.unsqueeze(-1)\n",
    "if X_test_t.dim() == 2:\n",
    "    X_test_t = X_test_t.unsqueeze(-1)\n",
    "\n",
    "print(f\"\\nTensor shapes (with feature dim):\")\n",
    "print(f\"X_train_t shape: {X_train_t.shape}\")\n",
    "print(f\"X_test_t shape: {X_test_t.shape}\")\n",
    "\n",
    "# --- Create DataLoaders ---\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 3. Model Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Model 1: LSTM Only\n",
    "\n",
    "This is a standard LSTM model. It consists of an `nn.LSTM` layer followed by an `nn.Linear` layer to produce the final prediction.\n",
    "\n",
    "**Architecture:**\n",
    "1.  Input `x` (batch, seq_len, 1) goes into the LSTM.\n",
    "2.  The LSTM outputs hidden states for all time steps.\n",
    "3.  We take the output from the *very last time step* (`lstm_out[:, -1, :]`).\n",
    "4.  This final hidden state is passed to a Linear layer to predict a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, output_size=1, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,  # Input shape is (batch_size, seq_len, features)\n",
    "            dropout=dropout    # Dropout between LSTM layers (if num_layers > 1)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states (defaults to zeros if not provided)\n",
    "        # h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Get LSTM outputs\n",
    "        # lstm_out shape: (batch_size, seq_len, hidden_size)\n",
    "        lstm_out, _ = self.lstm(x) # We don't need the final (h_n, c_n) here\n",
    "        \n",
    "        # We only want the output from the last time step\n",
    "        # lstm_out[:, -1, :] gives (batch_size, hidden_size)\n",
    "        last_time_step_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Pass the last output through the linear layer\n",
    "        prediction = self.fc(last_time_step_out)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Model 2: LSTM with Attention\n",
    "\n",
    "This model adds an attention mechanism to the LSTM. Instead of just using the *last* hidden state, the attention mechanism learns to assign different \"importance\" weights to the hidden states from *all* time steps. It then computes a weighted sum (the \"context vector\") of all hidden states, which is used for the final prediction.\n",
    "\n",
    "**Architecture:**\n",
    "1.  Input `x` goes into the LSTM, producing all hidden states `lstm_out` (batch, seq_len, hidden_size).\n",
    "2.  **Attention Calculation:**\n",
    "    a.  Pass `lstm_out` through a linear layer and `tanh` activation to get \"energy\" scores.\n",
    "    b.  Pass the energy scores through another linear layer to get raw scores (batch, seq_len, 1).\n",
    "    c.  Apply `softmax` along the time dimension to get attention weights (batch, seq_len, 1). These weights sum to 1.\n",
    "3.  **Context Vector:**\n",
    "    a.  Multiply the weights with the original `lstm_out` (element-wise).\n",
    "    b.  Sum the results across the time dimension to get a single context vector (batch, hidden_size).\n",
    "4.  Pass this context vector to the final Linear layer for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAttentionModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, output_size=1, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Attention layers\n",
    "        # This layer learns the 'energy' of each hidden state\n",
    "        self.attn_W = nn.Linear(hidden_size, hidden_size)\n",
    "        # This layer learns the 'v' vector to compute the final score\n",
    "        self.attn_v = nn.Linear(hidden_size, 1, bias=False)\n",
    "        \n",
    "        # Final prediction layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # lstm_out: (batch_size, seq_len, hidden_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # --- Attention Mechanism ---\n",
    "        # 1. Calculate energy\n",
    "        # (batch_size, seq_len, hidden_size) -> (batch_size, seq_len, hidden_size)\n",
    "        energy = torch.tanh(self.attn_W(lstm_out))\n",
    "        \n",
    "        # 2. Calculate scores\n",
    "        # (batch_size, seq_len, hidden_size) -> (batch_size, seq_len, 1)\n",
    "        scores = self.attn_v(energy)\n",
    "        \n",
    "        # 3. Get weights (softmax over time dimension, dim=1)\n",
    "        # (batch_size, seq_len, 1)\n",
    "        weights = torch.softmax(scores, dim=1)\n",
    "        \n",
    "        # 4. Calculate context vector\n",
    "        # (batch_size, seq_len, 1) * (batch_size, seq_len, hidden_size) -> (batch_size, seq_len, hidden_size)\n",
    "        weighted_out = weights * lstm_out\n",
    "        # Sum across time dimension: (batch_size, hidden_size)\n",
    "        context = torch.sum(weighted_out, dim=1)\n",
    "        # ---------------------------\n",
    "        \n",
    "        # Final prediction\n",
    "        prediction = self.fc(context)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 4. Training the Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### 4.1. Early Stopping Utility\n",
    "\n",
    "To prevent overfitting and save time, we'll implement an `EarlyStopping` class. It monitors the validation loss and stops training if it doesn't improve for a specified number of `patience` epochs. It also saves the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0, verbose=True, path='checkpoint.pth'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.inf\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"   ...Val loss improved to {val_loss:.6f}. Saving model to {self.path}...\")\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"   ...EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 4.2. Training Function\n",
    "\n",
    "This function contains the main training and validation loop. It's reusable for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, epochs, lr, patience, model_path):\n",
    "    criterion = nn.MSELoss()  # Mean Squared Error is suitable for regression\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    early_stopper = EarlyStopping(patience=patience, path=model_path, verbose=True)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    print(f\"--- Starting Training for {model_path} ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_train_loss = 0.0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_train_loss += loss.item() * X_batch.size(0)\n",
    "        \n",
    "        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        \n",
    "        # --- Validation ---\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                running_val_loss += loss.item() * X_batch.size(0)\n",
    "                \n",
    "        epoch_val_loss = running_val_loss / len(test_loader.dataset)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:03}/{epochs:03} | Train Loss: {epoch_train_loss:.6f} | Val Loss: {epoch_val_loss:.6f}\")\n",
    "        \n",
    "        # Check early stopping\n",
    "        early_stopper(epoch_val_loss, model)\n",
    "        if early_stopper.early_stop:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "            \n",
    "    end_time = time.time()\n",
    "    print(f\"--- Training Finished in {end_time - start_time:.2f}s ---\")\n",
    "    \n",
    "    # Load the best model state\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "def plot_losses(train_losses, val_losses, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### 4.3. Train Model 1 (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTMModel(\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ").to(DEVICE)\n",
    "\n",
    "lstm_model, lstm_train_loss, lstm_val_loss = train_model(\n",
    "    lstm_model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    EPOCHS,\n",
    "    LEARNING_RATE,\n",
    "    PATIENCE,\n",
    "    'models/best_lstm_model.pth' # Path to save best model\n",
    ")\n",
    "\n",
    "plot_losses(lstm_train_loss, lstm_val_loss, \"Model 1: LSTM Training & Validation Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### 4.4. Train Model 2 (LSTM + Attention)\n",
    "\n",
    "We train the attention model under the same conditions (same data, epochs, lr, etc.) for a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_model = LSTMAttentionModel(\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ").to(DEVICE)\n",
    "\n",
    "attention_model, attn_train_loss, attn_val_loss = train_model(\n",
    "    attention_model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    EPOCHS,\n",
    "    LEARNING_RATE,\n",
    "    PATIENCE,\n",
    "    'models/best_attention_model.pth' # Path to save best model\n",
    ")\n",
    "\n",
    "plot_losses(attn_train_loss, attn_val_loss, \"Model 2: LSTM + Attention Training & Validation Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Comparison\n",
    "\n",
    "### 5.1. Autoregressive Prediction\n",
    "\n",
    "This is the most critical part of the evaluation. We will simulate a real-world prediction scenario:\n",
    "1.  Take the **first window** from the test set (`X_test_t[0]`) as the initial input.\n",
    "2.  Predict the next value (Prediction 1).\n",
    "3.  Create a **new window** by *dropping* the first value of the initial window and *appending* Prediction 1 to the end.\n",
    "4.  Use this new window to predict the next value (Prediction 2).\n",
    "5.  Repeat this process for the entire length of the test set.\n",
    "\n",
    "This method tests the model's stability, as prediction errors will accumulate (compound) over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoregressive_predict(model, initial_window_tensor, n_predictions):\n",
    "    \"\"\"\n",
    "    Performs autoregressive prediction.\n",
    "    `initial_window_tensor` should have shape (window_size, 1).\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions = []\n",
    "    current_window = initial_window_tensor.clone().to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_predictions):\n",
    "            # Input must be (1, window_size, 1) for the model\n",
    "            input_tensor = current_window.unsqueeze(0)\n",
    "            \n",
    "            # Get prediction\n",
    "            pred = model(input_tensor)\n",
    "            \n",
    "            # Store the prediction (as a simple number)\n",
    "            predictions.append(pred.item())\n",
    "            \n",
    "            # Update the window for the next iteration\n",
    "            # `pred` shape is (1, 1). We need it as (1, 1) to concatenate\n",
    "            new_entry = pred.cpu() # Shape (1, 1)\n",
    "            \n",
    "            # Remove first element and append new prediction\n",
    "            # current_window[1:] is (window_size-1, 1)\n",
    "            current_window = torch.cat((current_window[1:], new_entry), dim=0)\n",
    "            \n",
    "    return np.array(predictions)\n",
    "\n",
    "# Get the first window from the test set\n",
    "# X_test_t shape is (N_test, window_size, 1). We need the first item.\n",
    "first_test_window = X_test_t[0]\n",
    "\n",
    "# Number of predictions to make == length of the test set\n",
    "n_test_predictions = len(y_test_t)\n",
    "\n",
    "print(\"Running autoregressive predictions for LSTM model...\")\n",
    "lstm_preds_autoregressive = autoregressive_predict(lstm_model, first_test_window, n_test_predictions)\n",
    "\n",
    "print(\"Running autoregressive predictions for Attention model...\")\n",
    "attn_preds_autoregressive = autoregressive_predict(attention_model, first_test_window, n_test_predictions)\n",
    "\n",
    "# Get actual values for comparison\n",
    "actuals = y_test_t.cpu().numpy().flatten()\n",
    "\n",
    "print(\"Predictions complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### 5.2. Metrics\n",
    "\n",
    "We'll use common regression metrics to compare the models:\n",
    "-   **MSE (Mean Squared Error):** Penalizes large errors heavily.\n",
    "-   **RMSE (Root Mean Squared Error):** MSE in the original units (log returns).\n",
    "-   **MAE (Mean Absolute Error):** Average absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(preds, actuals):\n",
    "    mse = mean_squared_error(actuals, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actuals, preds)\n",
    "    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae}\n",
    "\n",
    "lstm_metrics = calculate_metrics(lstm_preds_autoregressive, actuals)\n",
    "attn_metrics = calculate_metrics(attn_preds_autoregressive, actuals)\n",
    "\n",
    "print(\"--- Autoregressive Performance Metrics ---\")\n",
    "metrics_df = pd.DataFrame([lstm_metrics, attn_metrics], index=['LSTM Model', 'Attention Model'])\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### 5.3. Visualization: Predicted vs. Actual Relative Changes\n",
    "\n",
    "Let's plot the predicted log returns against the actual log returns. Due to the compounding error of autoregression, we expect the predictions to drift over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(actuals, label='Actual Log Returns', color='blue', alpha=0.7)\n",
    "plt.plot(lstm_preds_autoregressive, label='LSTM Predictions (Autoregressive)', color='orange', linestyle='--')\n",
    "plt.plot(attn_preds_autoregressive, label='Attention Predictions (Autoregressive)', color='green', linestyle=':')\n",
    "plt.legend()\n",
    "plt.title(f'Autoregressive Predictions vs Actuals (Log Returns) - Test Set')\n",
    "plt.xlabel('Time Step (in test set)')\n",
    "plt.ylabel('Log Return')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### 5.4. Visualization: Reconstructed Absolute Prices\n",
    "\n",
    "To make the results more intuitive, we will reconstruct the absolute prices from the predicted log returns.\n",
    "\n",
    "The formula is: $P_t = P_{t-1} \\cdot e^{\\text{log\\_return}_t}$\n",
    "\n",
    "We need a starting price, which will be the last *actual* price *before* the test set began."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_prices(start_price, log_returns):\n",
    "    \"\"\"Converts log returns back to absolute prices.\"\"\"\n",
    "    prices = [start_price]\n",
    "    current_price = start_price\n",
    "    for log_ret in log_returns:\n",
    "        current_price = current_price * np.exp(log_ret)\n",
    "        prices.append(current_price)\n",
    "    return np.array(prices)\n",
    "\n",
    "# --- Find the correct start price and actual test prices ---\n",
    "\n",
    "# `log_returns` is the pd.Series with the DatetimeIndex\n",
    "# `split_idx` was the split index on `X`\n",
    "# `y_test[0]` corresponds to `y[split_idx]`\n",
    "# `y[split_idx]` corresponds to `log_returns_np[split_idx + BASE_WINDOW_SIZE]`\n",
    "# This corresponds to the pandas Series `log_returns.iloc[split_idx + BASE_WINDOW_SIZE]`\n",
    "first_test_log_return_index = log_returns.index[split_idx + BASE_WINDOW_SIZE]\n",
    "\n",
    "# The start price is the price on the day *before* this first test log return\n",
    "# We find the original 'prices' index location *before* this timestamp\n",
    "start_price_timestamp = prices.index[prices.index < first_test_log_return_index][-1]\n",
    "start_price = prices.loc[start_price_timestamp].iloc[0]\n",
    "\n",
    "# The actual test prices start on `first_test_log_return_index`\n",
    "actual_test_prices_pd = prices.loc[first_test_log_return_index:]\n",
    "\n",
    "# Ensure it's the same length as our predictions\n",
    "actual_test_prices = actual_test_prices_pd.iloc[:len(actuals)].values\n",
    "\n",
    "print(f\"Reconstruction Start Price (on {start_price_timestamp.date()}): ${start_price:.2f}\")\n",
    "print(f\"Actual test prices to compare: {len(actual_test_prices)}\")\n",
    "print(f\"Predictions made: {len(actuals)}\")\n",
    "\n",
    "# --- Reconstruct prices from predictions ---\n",
    "lstm_recon_prices = reconstruct_prices(start_price, lstm_preds_autoregressive)\n",
    "attn_recon_prices = reconstruct_prices(start_price, attn_preds_autoregressive)\n",
    "\n",
    "# --- Plot reconstructed prices ---\n",
    "plt.figure(figsize=(15, 7))\n",
    "test_index = actual_test_prices_pd.iloc[:len(actuals)].index\n",
    "\n",
    "plt.plot(test_index, actual_test_prices, label='Actual Prices', color='blue', linewidth=2)\n",
    "plt.plot(test_index, lstm_recon_prices[1:], label='LSTM Reconstructed Prices', color='orange', linestyle='--')\n",
    "plt.plot(test_index, attn_recon_prices[1:], label='Attention Reconstructed Prices', color='green', linestyle=':')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f'Reconstructed Absolute Prices (Autoregressive) - {STOCK_TICKER}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## 6. Experimentation with Sliding Window Sizes\n",
    "\n",
    "Now we'll automate the process to test different window sizes (10, 25, 50, 100). \n",
    "\n",
    "**Note:** As per the assignment instructions, we will **only run this for the basic LSTM model** because training the attention model repeatedly is very time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_window_experiment(window_size, full_log_returns_data):\n",
    "    \"\"\"A complete pipeline to train and evaluate an LSTM model for a given window size.\"\"\"\n",
    "    print(f\"\\n{'='*20} RUNNING FOR WINDOW SIZE: {window_size} {'='*20}\")\n",
    "    \n",
    "    # 1. Data Prep\n",
    "    X, y = create_sliding_windows(full_log_returns_data, window_size)\n",
    "    if len(X) == 0:\n",
    "        print(\"Not enough data to create windows. Skipping.\")\n",
    "        return None\n",
    "    \n",
    "    split_idx = int(len(X) * TRAIN_SPLIT)\n",
    "    X_train, y_train = X[:split_idx], y[:split_idx]\n",
    "    X_test, y_test = X[split_idx:], y[split_idx:]\n",
    "    \n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    if len(X_test) == 0:\n",
    "        print(\"Test set is empty for this window size. Skipping.\")\n",
    "        return None\n",
    "        \n",
    "    X_train_t = torch.tensor(X_train).float()\n",
    "    y_train_t = torch.tensor(y_train).float()\n",
    "    X_test_t = torch.tensor(X_test).float()\n",
    "    y_test_t = torch.tensor(y_test).float()\n",
    "\n",
    "    # Add the feature dimension *only if* it's not already there\n",
    "    if X_train_t.dim() == 2:\n",
    "        X_train_t = X_train_t.unsqueeze(-1)\n",
    "    if X_test_t.dim() == 2:\n",
    "        X_test_t = X_test_t.unsqueeze(-1)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_dataset = TensorDataset(X_test_t, y_test_t)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # 2. Model Training\n",
    "    model = LSTMModel(\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        dropout=DROPOUT\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    model, _, _ = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        EPOCHS,\n",
    "        LEARNING_RATE,\n",
    "        PATIENCE,\n",
    "        f'models/lstm_model_w{window_size}.pth'\n",
    "    )\n",
    "    \n",
    "    # 3. Autoregressive Evaluation\n",
    "    first_test_window = X_test_t[0]\n",
    "    n_test_predictions = len(y_test_t)\n",
    "    preds = autoregressive_predict(model, first_test_window, n_test_predictions)\n",
    "    actuals = y_test_t.cpu().numpy().flatten()\n",
    "    \n",
    "    # 4. Calculate Metrics\n",
    "    metrics = calculate_metrics(preds, actuals)\n",
    "    metrics['window_size'] = window_size\n",
    "    \n",
    "    print(f\"--- Metrics for window {window_size}: {metrics} ---\")\n",
    "    return metrics\n",
    "\n",
    "# --- Run the Experiments ---\n",
    "window_sizes = [10, 25, 50, 100]\n",
    "experiment_results = []\n",
    "\n",
    "for ws in window_sizes:\n",
    "    result = run_window_experiment(ws, log_returns_np)\n",
    "    if result:\n",
    "        experiment_results.append(result)\n",
    "\n",
    "# --- Compare Results ---\n",
    "print(\"\\n\\n{'='*20} FINAL WINDOW SIZE COMPARISON {'='*20}\")\n",
    "results_df = pd.DataFrame(experiment_results).set_index('window_size')\n",
    "display(results_df)\n",
    "\n",
    "# Plot the results\n",
    "results_df.plot(kind='bar', subplots=True, layout=(1, 3), figsize=(18, 5), title=\"LSTM Model Performance by Window Size\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
